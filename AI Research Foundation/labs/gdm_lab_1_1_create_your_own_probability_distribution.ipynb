{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MadhuryaPasan/Google-Skills/blob/main/AI%20Research%20Foundation/labs/gdm_lab_1_1_create_your_own_probability_distribution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DAsej7XSlYt"
      },
      "source": [
        "> <p><small><small>This Notebook is made available subject to the licence and terms set out in the <a href = \"http://www.github.com/google-deepmind/ai-foundations\">AI Research Foundations Github README file</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3myzQnLMOJ91"
      },
      "source": [
        "<img src=\"https://storage.googleapis.com/dm-educational/assets/ai_foundations/GDM-Labs-banner-image-C1-white-bg.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE0jaJsaICiX"
      },
      "source": [
        "# Lab: Create Your Own Probability Distribution\n",
        "\n",
        "<a href='https://colab.research.google.com/github/google-deepmind/ai-foundations/blob/master/course_1/gdm_lab_1_1_create_your_own_probability_distribution.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>\n",
        "\n",
        "Explore the fundamentals of language models by predicting the next word in a given text prompt.\n",
        "\n",
        "15 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSYq3aNrdpnC"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In the previous activities, you have been introduced to language models. Fundamentally, a language model assigns a probability distribution to the next word for a given **context**. In later parts of this course, you will learn how you can build models that automatically compute these probability distributions. But before that, it is important that you get a sense of how these probability distributions are used to predict the next word.\n",
        "\n",
        "In this lab, you will generate continuations for prompts by randomly choosing words from a probability distribution. A **prompt** is the input text provided to a language model. The goal is to assign probability values to a set of candidate words based on the context defined by the prompt. Then randomly choose from this list, a process known as **sampling**, to generate the next word. You will investigate how probabilities influence the generation of language and practice manipulating these probabilities to create sensible sentences. In doing so, you will mimick the basic principles of language models.\n",
        "\n",
        "The prompt you will use throughout this course is \"Jide was hungry so she went looking for.\" It is adapted from the prompt featured in Eldan and Li's 2023 paper [_TinyStories: How Small Can Language Models Be and Still Speak Coherent English?_](https://arxiv.org/pdf/2305.07759) [1].\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4Qf3eGhfl4H"
      },
      "source": [
        "### What you will learn:\n",
        "\n",
        "By the end of this lab, you will understand:\n",
        "\n",
        "* How probabilities influence the choice of the next word.\n",
        "* How the context should determine the probability distribution over the next word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIhcVxx0foVo"
      },
      "source": [
        "### Tasks\n",
        "\n",
        "**In this lab, you will**:\n",
        "* Assign probabilities to each candidate word reflecting the likelihood of it being the appropriate next word given the prompt.\n",
        "* Use the `random.choices` function with the assigned probabilities to sample a candidate word.\n",
        "* Explore how altering the prompt (e.g., changing *hungry* to *thirsty* or modifying the subject) influences the probability distribution and the predicted next word.\n",
        "\n",
        "All of these steps are described in detail in the following sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDWsJUGcf4Ru"
      },
      "source": [
        "## How to use Google Colaboratory (Colab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlNG_jg-39Zj"
      },
      "source": [
        "Google Colaboratory (also known as Google Colab) is a platform that allows you to run Python code in your browser. The code is written in **cells** that are excuted on a remote server.\n",
        "\n",
        "To run a cell, hover over the cell and click on the `run` button to its left. The run button is the circle with the triangle (▶). Alternatively, you can also click on a cell and use the keyboard combination Ctrl+Return (or ⌘+Return if you are using a Mac).\n",
        "\n",
        "To try this out, run the following cell. This should print today's day of the week below it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyTT6C0JhGBs",
        "outputId": "86cf2ef9-e1c3-42dc-e940-4a8bdb761fd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Today is Monday.\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "print(f\"Today is {datetime.today():%A}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbtgZxrpjm6j"
      },
      "source": [
        "Note that the *order in which you run the cells matters*. When you are working through a lab, make sure to always run *all* cells in order, otherwise the code might not work. If you take a break while working on a lab, Colab may disconnect you and in that case, you have to execute all cells again before  continuing your work. To make this easier, you can select the cell you are currently working on and then choose __Runtime → Run before__  from the menu above (or use the keyboard combination Ctrl/⌘ + F8). This will re-execute all cells before the current one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-d1hd7Xndke"
      },
      "source": [
        "## Imports\n",
        "\n",
        "In this lab, you will make use of the `random` package to randomly pick elements from a probability distribution. All labs also use functions from the custom `ai_foundations` package that implements specific functionality for this course, such as automatic tests for verifying your answers.\n",
        "\n",
        "Run the following cell to import the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qsVTBvhBJTFZ",
        "outputId": "518941b4-46dd-4e45-eb9a-309a2f12aebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/google-deepmind/ai-foundations.git@main\n",
            "  Cloning https://github.com/google-deepmind/ai-foundations.git (to revision main) to /tmp/pip-req-build-gix2z5yt\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google-deepmind/ai-foundations.git /tmp/pip-req-build-gix2z5yt\n",
            "  Resolved https://github.com/google-deepmind/ai-foundations.git to commit c7dad0d118fcd15b797c1bf2f7e8d49291b4cd45\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gemma==3.0.0 (from ai_foundations==0.1.0)\n",
            "  Downloading gemma-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: jax==0.7.2 in /usr/local/lib/python3.12/dist-packages (from ai_foundations==0.1.0) (0.7.2)\n",
            "Requirement already satisfied: keras==3.10.0 in /usr/local/lib/python3.12/dist-packages (from ai_foundations==0.1.0) (3.10.0)\n",
            "Requirement already satisfied: numpy==2.0.2 in /usr/local/lib/python3.12/dist-packages (from ai_foundations==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.12/dist-packages (from ai_foundations==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: plotly==5.24.1 in /usr/local/lib/python3.12/dist-packages (from ai_foundations==0.1.0) (5.24.1)\n",
            "Requirement already satisfied: IPython==7.34.0 in /usr/local/lib/python3.12/dist-packages (from ai_foundations==0.1.0) (7.34.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from gemma==3.0.0->ai_foundations==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: etils[edc,enp,epath,epy,etree] in /usr/local/lib/python3.12/dist-packages (from gemma==3.0.0->ai_foundations==0.1.0) (1.13.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from gemma==3.0.0->ai_foundations==0.1.0) (0.8.1)\n",
            "Collecting grain (from gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading grain-0.2.15-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
            "Collecting jaxtyping (from gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading jaxtyping-0.3.5-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting kauldron (from gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading kauldron-1.3.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.12/dist-packages (from gemma==3.0.0->ai_foundations==0.1.0) (0.10.7)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.12/dist-packages (from gemma==3.0.0->ai_foundations==0.1.0) (0.11.31)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from gemma==3.0.0->ai_foundations==0.1.0) (0.2.1)\n",
            "Requirement already satisfied: treescope in /usr/local/lib/python3.12/dist-packages (from gemma==3.0.0->ai_foundations==0.1.0) (0.1.10)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from IPython==7.34.0->ai_foundations==0.1.0) (75.2.0)\n",
            "Collecting jedi>=0.16 (from IPython==7.34.0->ai_foundations==0.1.0)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from IPython==7.34.0->ai_foundations==0.1.0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from IPython==7.34.0->ai_foundations==0.1.0) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from IPython==7.34.0->ai_foundations==0.1.0) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from IPython==7.34.0->ai_foundations==0.1.0) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from IPython==7.34.0->ai_foundations==0.1.0) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from IPython==7.34.0->ai_foundations==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from IPython==7.34.0->ai_foundations==0.1.0) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from IPython==7.34.0->ai_foundations==0.1.0) (4.9.0)\n",
            "Requirement already satisfied: jaxlib<=0.7.2,>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from jax==0.7.2->ai_foundations==0.1.0) (0.7.2)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax==0.7.2->ai_foundations==0.1.0) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax==0.7.2->ai_foundations==0.1.0) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax==0.7.2->ai_foundations==0.1.0) (1.16.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras==3.10.0->ai_foundations==0.1.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras==3.10.0->ai_foundations==0.1.0) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras==3.10.0->ai_foundations==0.1.0) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras==3.10.0->ai_foundations==0.1.0) (0.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras==3.10.0->ai_foundations==0.1.0) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->ai_foundations==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->ai_foundations==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->ai_foundations==0.1.0) (2025.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly==5.24.1->ai_foundations==0.1.0) (9.1.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->IPython==7.34.0->ai_foundations==0.1.0) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->IPython==7.34.0->ai_foundations==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython==7.34.0->ai_foundations==0.1.0) (0.2.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2->ai_foundations==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]->gemma==3.0.0->ai_foundations==0.1.0) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]->gemma==3.0.0->ai_foundations==0.1.0) (6.5.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]->gemma==3.0.0->ai_foundations==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]->gemma==3.0.0->ai_foundations==0.1.0) (3.23.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from flax->gemma==3.0.0->ai_foundations==0.1.0) (1.1.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.12/dist-packages (from flax->gemma==3.0.0->ai_foundations==0.1.0) (0.2.6)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.12/dist-packages (from flax->gemma==3.0.0->ai_foundations==0.1.0) (0.1.80)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from flax->gemma==3.0.0->ai_foundations==0.1.0) (6.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras==3.10.0->ai_foundations==0.1.0) (4.0.0)\n",
            "Requirement already satisfied: array-record>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from grain->gemma==3.0.0->ai_foundations==0.1.0) (0.8.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from grain->gemma==3.0.0->ai_foundations==0.1.0) (3.1.2)\n",
            "Requirement already satisfied: protobuf>=5.28.3 in /usr/local/lib/python3.12/dist-packages (from grain->gemma==3.0.0->ai_foundations==0.1.0) (5.29.5)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping->gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.12/dist-packages (from kauldron->gemma==3.0.0->ai_foundations==0.1.0) (5.5.0)\n",
            "Requirement already satisfied: chex in /usr/local/lib/python3.12/dist-packages (from kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.1.90)\n",
            "Collecting clu (from kauldron->gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading clu-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.21)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.12/dist-packages (from kauldron->gemma==3.0.0->ai_foundations==0.1.0) (4.2.2)\n",
            "Requirement already satisfied: lark in /usr/local/lib/python3.12/dist-packages (from kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.3.1)\n",
            "Collecting mediapy (from kauldron->gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading mediapy-1.2.5-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting ml_collections (from kauldron->gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading ml_collections-1.1.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from kauldron->gemma==3.0.0->ai_foundations==0.1.0) (4.12.0.88)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.6.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.9.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (from kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.19.0)\n",
            "Requirement already satisfied: tensorflow_datasets>=4.9.7 in /usr/local/lib/python3.12/dist-packages (from kauldron->gemma==3.0.0->ai_foundations==0.1.0) (4.9.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kauldron->gemma==3.0.0->ai_foundations==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: typeguard>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from kauldron->gemma==3.0.0->ai_foundations==0.1.0) (4.4.4)\n",
            "Collecting xmanager (from kauldron->gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading xmanager-0.7.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->gemma==3.0.0->ai_foundations==0.1.0) (1.6.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->gemma==3.0.0->ai_foundations==0.1.0) (24.1.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->gemma==3.0.0->ai_foundations==0.1.0) (4.14.0)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->gemma==3.0.0->ai_foundations==0.1.0) (3.20.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->gemma==3.0.0->ai_foundations==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.10.0->ai_foundations==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets>=4.9.7->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.1.9)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets>=4.9.7->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.3)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets>=4.9.7->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (18.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets>=4.9.7->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.32.4)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets>=4.9.7->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets>=4.9.7->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.17.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets>=4.9.7->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets>=4.9.7->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets>=4.9.7->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.0.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.13.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chex->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapy->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from mediapy->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (11.3.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (3.6.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2025.12.12)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (18.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.19.0)\n",
            "Collecting alembic==1.4.3 (from xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading alembic-1.4.3-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting async_generator (from xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading async_generator-1.10-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (25.4.0)\n",
            "Collecting cloud-sql-python-connector (from xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading cloud_sql_python_connector-1.19.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting docker (from xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.187.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.12/dist-packages (from xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.43.0)\n",
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.12/dist-packages (from xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.130.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (from xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (3.7.0)\n",
            "Collecting kubernetes (from xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting sqlalchemy==1.2.19 (from xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading SQLAlchemy-1.2.19.tar.gz (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.12/dist-packages (from xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.5.4)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic==1.4.3->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.3.10)\n",
            "Collecting python-editor>=0.3 (from alembic==1.4.3->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.45.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.30.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->tensorflow_datasets>=4.9.7->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->tensorflow_datasets>=4.9.7->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->tensorflow_datasets>=4.9.7->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->tensorflow_datasets>=4.9.7->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from cloud-sql-python-connector->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (3.13.2)\n",
            "Requirement already satisfied: cryptography>=42.0.0 in /usr/local/lib/python3.12/dist-packages (from cloud-sql-python-connector->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (43.0.3)\n",
            "Collecting dnspython>=2.0.0 (from cloud-sql-python-connector->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (4.9.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.72.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.26.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (4.2.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (3.38.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.15.0)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.1.2)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.37.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.55.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.12.3)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.17.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.8.0)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (3.0.3)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.0.0)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.19.0->tensorflow_datasets>=4.9.7->kauldron->gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (3.2.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=42.0.0->cloud-sql-python-connector->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.0.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.71.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.14.3)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (4.12.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.28.1)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.6.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->cloud-sql-python-connector->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->cloud-sql-python-connector->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->cloud-sql-python-connector->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->cloud-sql-python-connector->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->cloud-sql-python-connector->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->cloud-sql-python-connector->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.22.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (3.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=42.0.0->cloud-sql-python-connector->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (2.23)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform->xmanager->kauldron->gemma==3.0.0->ai_foundations==0.1.0) (0.16.0)\n",
            "Downloading gemma-3.0.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grain-0.2.15-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (504 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.3/504.3 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxtyping-0.3.5-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kauldron-1.3.0-py3-none-any.whl (492 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.3/492.3 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
            "Downloading clu-0.0.12-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mediapy-1.2.5-py3-none-any.whl (27 kB)\n",
            "Downloading ml_collections-1.1.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xmanager-0.7.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.4.3-py2.py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Downloading cloud_sql_python_connector-1.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ai_foundations, sqlalchemy\n",
            "  Building wheel for ai_foundations (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ai_foundations: filename=ai_foundations-0.1.0-py3-none-any.whl size=107544 sha256=c298fb53f7d66ae3dde86610ef2f0ae8b69994a4fe1f88d95e9234c290474a1c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gap2u3zj/wheels/9c/15/85/4a872ca79c4bf53f92f6811417945b900de3a0d8ffd3565896\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.2.19-cp312-cp312-linux_x86_64.whl size=1146660 sha256=097283b202c128c23cf4c41170a7535fc8d863c3d66854062b67c643f99f9b1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/7e/50/84e9e1171b9f75c3c2c401f9360cf19609f1e07087d721e480\n",
            "Successfully built ai_foundations sqlalchemy\n",
            "Installing collected packages: sqlalchemy, python-editor, durationpy, wadler-lindig, urllib3, ml_collections, jedi, dnspython, async_generator, jaxtyping, alembic, mediapy, docker, cloud-sql-python-connector, kubernetes, grain, xmanager, clu, kauldron, gemma, ai_foundations\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.45\n",
            "    Uninstalling SQLAlchemy-2.0.45:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.45\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: alembic\n",
            "    Found existing installation: alembic 1.17.2\n",
            "    Uninstalling alembic-1.17.2:\n",
            "      Successfully uninstalled alembic-1.17.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.21.0 requires sqlalchemy<3.0.0,>=2.0, but you have sqlalchemy 1.2.19 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.2.19 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ai_foundations-0.1.0 alembic-1.4.3 async_generator-1.10 cloud-sql-python-connector-1.19.0 clu-0.0.12 dnspython-2.8.0 docker-7.1.0 durationpy-0.10 gemma-3.0.0 grain-0.2.15 jaxtyping-0.3.5 jedi-0.19.2 kauldron-1.3.0 kubernetes-34.1.0 mediapy-1.2.5 ml_collections-1.1.0 python-editor-1.0.4 sqlalchemy-1.2.19 urllib3-2.3.0 wadler-lindig-0.1.7 xmanager-0.7.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "f21256672c3d4d8888631772d43ad1ed"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# %%capture # used to silence or capture the output of a code cell.\n",
        "# Install the custom package for this course.\n",
        "%pip install \"git+https://github.com/google-deepmind/ai-foundations.git@main\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZPy-Uxih7Xuz"
      },
      "outputs": [],
      "source": [
        "# Packages used.\n",
        "# For randomly picking elements from a probability distribution.\n",
        "import random\n",
        "# Custom functions for providing feedback on your solutions.\n",
        "from ai_foundations.feedback.course_1 import probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXogrTsoaefb"
      },
      "source": [
        "## Assigning probabilities\n",
        "\n",
        "In the following activities, you will assign probabilities to candidate words. Candidate words for a prompt are words that could serve as continuations for the prompt.\n",
        "\n",
        "The cell below sets the probabilities for candidate words \"star\", \"beef\", \"bottle\" to complete the example prompt \"Twinkle twinkle little\". As you can see a high probability has been assigned to the word \"star\". This is to complete the prompt after the famous children's lullaby \"Twinkle, Twinkle Little Star\".\n",
        "\n",
        "You do not have to modify anything in the following cell but go through it closely. The following activities will ask you to implement something very similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "icYkPlVair-Q",
        "outputId": "ceb9f79c-3bb1-4ff7-a09c-9de98e03d190",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ You've set the probabilities successfully. Well done!\n"
          ]
        }
      ],
      "source": [
        "candidate_words = [\"star\", \"beef\", \"bottle\"]\n",
        "\n",
        "# The probabilities for each word are defined in the following list.\n",
        "your_mental_model = [0.99, 0.001, 0.009]\n",
        "\n",
        "# This function runs several checks to verify that your_mental_model defines\n",
        "# a proper probability distribution.\n",
        "probabilities.test_probabilities(candidate_words, your_mental_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ7GJRyZm5wo"
      },
      "source": [
        "------\n",
        "_Throughout the labs, you will see info boxes like this that provide you with background on how to use a function or explain key concepts. Make sure to familiarize yourself with the information in these boxes as you will need it to complete the following exercises._\n",
        "> ℹ️ **Info: `random.choices`**\n",
        ">\n",
        "> The `random.choices` function allows you to select an item from a list based on specified weights. In this case, the candidate words (e.g. *star*, *beef*, *bottle*) will have probabilities (weights) that sum to 1. When you call `random.choices` with your list of words and their corresponding weights, it will randomly select a word according to these probabilities. For more details on the random.choices function, refer to [Python - random.choices method](https://www.geeksforgeeks.org/random-choices-method-in-python/).\n",
        "------\n",
        "\n",
        "<br />\n",
        "\n",
        "The cell below completes the prompt based on the probabilities you assigned in the previous cell. Run the cell to complete the prompt.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JmLQmXVIjgwe",
        "outputId": "a94c9b60-7980-417c-a514-a7b791183b5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Twinkle twinkle little star.\n"
          ]
        }
      ],
      "source": [
        "chosen_word = random.choices(candidate_words, weights=your_mental_model)\n",
        "\n",
        "print(f\"Twinkle twinkle little {chosen_word[0]}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teWlko-_jq7J"
      },
      "source": [
        "### Coding Activity 1: Assigning probabilities for a different prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPqCBIUKjKYu"
      },
      "source": [
        "\n",
        "Now you will repeat this process for another prompt, namely \"Jide was hungry so she went looking for.\" The cell below already defines a list of words that serve as candidates for continuing this prompt: `[\"food\", \"snacks\", \"leftovers\", \"her\", \"for\", \"water\", \"photosynthesis\", \"pyramid\"]`.\n",
        "\n",
        "<br />\n",
        "\n",
        "------\n",
        "_Throughout the labs, you will see boxes like this that provide you with instructions on how to implement functionality. Follow the instructions closely and run the following cells once you are done._\n",
        "\n",
        "> 💻 **Your task:**\n",
        ">\n",
        "> Enter probabilities for each candidate word for the variable `your_mental_model`. Follow the format introduced in the cell shown above.\n",
        ">\n",
        ">Note that\n",
        ">1. your probabilities must add up to 1,\n",
        ">2. all probabilities must be greater or equal to 0,\n",
        ">3. you have to define a probability for each candidate word.\n",
        ">\n",
        "> Once you have entered your probabilities, run the cell.\n",
        "------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Urb2zkFM9a2a",
        "outputId": "d3c4d909-e17a-46f6-90bf-6ea0f471afbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ You've set the probabilities successfully. Well done!\n"
          ]
        }
      ],
      "source": [
        "candidate_words = [\n",
        "    \"food\",\n",
        "    \"snacks\",\n",
        "    \"leftovers\",\n",
        "    \"her\",\n",
        "    \"for\",\n",
        "    \"water\",\n",
        "    \"photosynthesis\",\n",
        "    \"pyramid\",\n",
        "]\n",
        "\n",
        "# Enter the probabilities for the candidate words to follow the\n",
        "# prompt \"Jide was hungry so she went looking for\".\n",
        "your_mental_model = [0.30, 0.25, 0.25, 0.15,0.005, 0.04, 0.004, 0.001]\n",
        "\n",
        "# This function runs several checks to verify that your_mental_model defines\n",
        "# a proper probability distribution.\n",
        "probabilities.test_probabilities(candidate_words, your_mental_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnpziVU2_lXE"
      },
      "source": [
        "Now, use the `random.choices` function to select the candidate words. Run this cell multiple times, and observe which words are chosen more frequently. Notice how the sentence changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jJD4BndPAAp-",
        "outputId": "4dc0633c-a0df-493d-f3db-7291620a20a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jide was hungry so she went looking for snacks ...\n"
          ]
        }
      ],
      "source": [
        "chosen_word = random.choices(candidate_words, weights=your_mental_model)\n",
        "\n",
        "print(f\"Jide was hungry so she went looking for {chosen_word[0]} ...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXb-VTdjgTxr"
      },
      "source": [
        "## Coding Activity 2: The importance of context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSboC6xUBD92"
      },
      "source": [
        "A good language model is sensitive to the given context. For example, if you are using a language model to build a chatbot, you want the model to generate answers that are relevant to the user's input rather than generating a response that talks about an irrelevant topic.\n",
        "\n",
        "In the next activity, you will observe how a change in context should alter the probability distribution of the next word. Consider another prompt that is very similar to the prompt above: \"Jide was thirsty so she went looking for.\"\n",
        "\n",
        "With this context in mind, reassess the candidate words, and update your probability estimates. Reflect on how being *thirsty* might change the probabilities of the next possible words for this prompt. Compare it with the original prompt, in which Jide was *hungry*.\n",
        "\n",
        "\n",
        "The list of candidate words is the same: \"food\", \"snacks\", \"leftovers\", \"her\", \"for\", \"water\", \"photosynthesis\", and \"pyramid`.\n",
        "\n",
        "<br />\n",
        "\n",
        "------\n",
        "> 💻 **Your task:**\n",
        ">\n",
        "> Assign new probabilities for the candidate words based on the new prompt. Make sure you define a proper probabilitiy distribution such that probabilities are non-negative and sum to 1.\n",
        ">\n",
        "> Once you have entered your probabilities, run the cell.\n",
        "------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "s8wmmLbkBXcj",
        "outputId": "a53c6bd8-1a02-42de-f9e7-645b2c3be280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ You've set the probabilities successfully. Well done!\n"
          ]
        }
      ],
      "source": [
        "candidate_words = [\n",
        "    \"food\",\n",
        "    \"snacks\",\n",
        "    \"leftovers\",\n",
        "    \"her\",\n",
        "    \"for\",\n",
        "    \"water\",\n",
        "    \"photosynthesis\",\n",
        "    \"pyramid\",\n",
        "]\n",
        "\n",
        "# Enter the probabilities for the candidate words to follow the\n",
        "# prompt \"Jide was thirsty so she went looking for\".\n",
        "your_mental_model = [0.01,0.02,0.01,0.03,0.01,0.90,0.01,0.01]\n",
        "\n",
        "# This function runs several checks to verify that your_mental_model defines\n",
        "# a proper probability distribution.\n",
        "probabilities.test_probabilities(candidate_words, your_mental_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eFIFz2OqkUH"
      },
      "source": [
        "Run the cell below and observe how the `random.choices` function completes the prompt with the new probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1S0WN2Y2BjTD",
        "outputId": "003af127-365b-4549-e7b7-12e035d3df94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jide was thirsty so she went looking for water...\n"
          ]
        }
      ],
      "source": [
        "chosen_word = random.choices(candidate_words, weights=your_mental_model)\n",
        "\n",
        "print(f\"Jide was thirsty so she went looking for {chosen_word[0]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdi1RxLaLvIi"
      },
      "source": [
        "------\n",
        "_Throughout the labs, you will see reflection boxes like this that provide you with some questions to think about. If you would like to write your thoughts down, you can either add cells to this Colab notebook or take notes on [Google Docs](https://docs.google.com/), [Notebook LM](https://notebooklm.google/), a piece of paper, or any other note-taking tool of your choice. For the reflection activities, you will not have to write any additional code._\n",
        "\n",
        "\n",
        "> 💭 **Reflection:**\n",
        ">\n",
        "> Now, take a moment to reflect. For which words did you change the probabilities in the new context? Consider how modifying the prompt influenced your choice of probabilities. Which aspect of the new context made certain words stand out while others faded? Reflecting on the changes in the probability distribution that you applied can provide insights into how an ideal language model adjusts its word probabilities to generate **context-aware** responses.\n",
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgvnYCdruOtW"
      },
      "source": [
        "## Summary\n",
        "\n",
        "This is the end of the **Create Your Own Probability Distribution** lab.\n",
        "\n",
        "This notebook explored fundamental concepts of language models, focusing on:\n",
        "\n",
        "1. **Assigning probabilities:** You learned how to assign probabilities to candidate words based on a given prompt and you used the `random.choices` function to simulate word selection based on these probabilities. This highlighted the **stochastic** (or random) nature of language models, where word choices are guided by probabilities rather than always following the same generation process.\n",
        "\n",
        "2. **The impact of context:** You observed how changing the context of a prompt significantly alters the probability distribution of candidate words. You did this by comparing the probabilities that you assigned for the candidate words for the prompts \"Jide was hungry...\" versus \"Jide was thirsty...\". This highlighted how context influences word choices. This is an important concept for building modern language models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbCry1ll6L9g"
      },
      "source": [
        "## Solutions\n",
        "\n",
        "The following cells provide reference solutions to the coding activities above. If you really get stuck after trying to solve the activities yourself, you may want to consult these solutions.\n",
        "\n",
        "We recommend that you *only* look at the solutions after you have tried to solve the activities above *multiple times*. The best way to learn challenging concepts in computer science and artifical intelligence is to debug your code piece-by-piece until it works rather than copying existing solutions.\n",
        "\n",
        "If you feel stuck, you may want to first try to debug your code. For example, by adding additional print statements to see what your code is doing at every step. This will provide you with a much deeper understanding of the code and the materials. It will also provide you with practice on how to solve challenging coding problems beyond this course.\n",
        "\n",
        "To view the solutions for an activity, click on the arrow to the left of the activity name. If you consult the solutions, do not copy and paste them into the cells above. Instead, look at them and then type them manually into the cell. This will help you understand where you went wrong."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NJgcGxO6UDE"
      },
      "source": [
        "### Coding Activity 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UD38Eu8K7sXg"
      },
      "outputs": [],
      "source": [
        "# Add this code in the cell for Activity 1 above.\n",
        "your_mental_model=[0.2, 0.346, 0.2, 0.09, 0.001, 0.16, 0.002, 0.001]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYxczrMh8weO"
      },
      "source": [
        "### Coding Activity 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsdbWiyvAqso"
      },
      "outputs": [],
      "source": [
        "# Add this code in the cell for Activity 2 above.\n",
        "your_mental_model=[0.05, 0.046, 0.09, 0.05, 0.001, 0.76, 0.002, 0.001]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwwgTmVkFvte"
      },
      "source": [
        "## References\n",
        "\n",
        "[1] Ronen Eldan and Yuanzhi Li. 2023. Tiny Stories: How Small Can Language Models Be and Still Speak Coherent English. arXiv:2305.07759. Retrieved from [https://arxiv.org/pdf/2305.07759](https://arxiv.org/pdf/2305.07759).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TbCry1ll6L9g",
        "4NJgcGxO6UDE",
        "AYxczrMh8weO"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}